{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ENC9zzVUw1UP"
      },
      "outputs": [],
      "source": [
        "#---general purpose libraries--\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "#----for model bulding -----------\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#---for model evaluation\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#--for text processing----\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string\n",
        "import re\n",
        "#---for pipelining-----\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YAv0--0Tw1UW"
      },
      "outputs": [],
      "source": [
        "#----------FUNCTION DEFINITIONS -------------------\n",
        "\n",
        "#--function to preprocess text\n",
        "#--> Removes numbers from the text\n",
        "#--> Removes punctuation marks from the text\n",
        "#--> Returns array\n",
        "def preprocess(text):\n",
        "    return re.findall(r'(?:[a-zA-Z]+[a-zA-Z\\'\\-]?[a-zA-Z]|[a-zA-Z]+)',text)\n",
        "\n",
        "#--function to print performnace report-\n",
        "def performance_report(true,pred):\n",
        "    print(confusion_matrix(true, pred))\n",
        "    print(classification_report(true, pred))\n",
        "#----------FUNCTION DEFINITIONS ENDS HERE-------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5RwlOgNDw1UY"
      },
      "outputs": [],
      "source": [
        "#process the file which has user query and retreived procuct to create 2 create 2 different arrays product and user_query\n",
        "training = open('/content/training.txt')\n",
        "product=[]\n",
        "user_query=[]\n",
        "first_line = 1\n",
        "for line in training:\n",
        "    if first_line==1:\n",
        "        first_line = 0\n",
        "        continue\n",
        "    input_txt = line.strip().split(\"\\t\")\n",
        "    processed_txt = ' '.join(txt for txt in preprocess(input_txt[0]))\n",
        "    product.append(processed_txt)\n",
        "    user_query.append(input_txt[1])\n",
        "x_train=product\n",
        "y_train=user_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_1Jr_8Ubw1UZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c37415b-f1af-4ffe-f0ca-d36bffdbe7e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorize', TfidfVectorizer(stop_words='english')),\n",
              "                ('predictive_model', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#create pipeline for vectorizing the text(also removes stop words) input and then creating model sequentially\n",
        "x_train=product\n",
        "y_train=user_query\n",
        "\n",
        "#pred_model=Pipeline([('vectorize',TfidfVectorizer(stop_words='english')),('predictive_model', MultinomialNB())])\n",
        "pred_model=Pipeline([('vectorize',TfidfVectorizer(stop_words='english')),\n",
        "                   ('predictive_model', RandomForestClassifier())])\n",
        "pred_model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "J3OfNWv2w1Ub"
      },
      "outputs": [],
      "source": [
        "#--process the sample input--\n",
        "#--apply preprocessing on the text\n",
        "test_prdct=[]\n",
        "sample_input = open('/content/Sample_Input.txt')\n",
        "\n",
        "first_line = 1\n",
        "for line in sample_input:\n",
        "    if first_line==1:\n",
        "        first_line = 0\n",
        "        continue\n",
        "    input_txt = line.strip()\n",
        "    txt = ' '.join(preprocess(input_txt))\n",
        "    test_prdct.append(txt)\n",
        "x_test = np.array(test_prdct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "85eNPRoKw1Ud"
      },
      "outputs": [],
      "source": [
        "#--predict the corresponding query with the model\n",
        "pred_query=pred_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "n-QPeCMcw1Ud"
      },
      "outputs": [],
      "source": [
        "#Lets import sample output to compare with predicted output\n",
        "test_user_query = []\n",
        "sample_output = open('/content/Sample_Output.txt') \n",
        "for line in sample_output:\n",
        "    test_user_query.append(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "giBDgeHuw1Uf"
      },
      "outputs": [],
      "source": [
        "#--create dataframe to store the predicted Vs actual result\n",
        "df_predicted_vs_actual = pd.DataFrame(\n",
        "    {'Product': test_prdct,\n",
        "     'Actual_User_Query': test_user_query,\n",
        "     'Predicted_User_Query': pred_query\n",
        "    })\n",
        "#df_predicted_vs_actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "PXBMaKQ9w1Ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192d41f5-8e50-4d76-86ec-6d46d528d57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "          athleisure women       0.00      0.00      0.00         1\n",
            "                   axe deo       0.00      0.00      0.00         1\n",
            "                   bandana       1.00      1.00      1.00         1\n",
            "               beach dress       0.00      0.00      0.00         1\n",
            "                   beanies       1.00      1.00      1.00         1\n",
            "              biker gloves       1.00      1.00      1.00         1\n",
            "              biker jacket       1.00      1.00      1.00         1\n",
            "              biker shorts       0.50      1.00      0.67         1\n",
            "                 bodysuits       1.00      1.00      1.00         1\n",
            "           boyfriend jeans       0.50      1.00      0.67         1\n",
            "                  bralette       1.00      1.00      1.00         1\n",
            "          buttondown skirt       0.33      1.00      0.50         1\n",
            "              combat shoes       1.00      1.00      1.00         1\n",
            "                    corset       1.00      1.00      1.00         1\n",
            "              cowboy boots       1.00      1.00      1.00         1\n",
            "                     crocs       1.00      1.00      1.00         1\n",
            "                 crop tops       0.00      0.00      0.00         1\n",
            "            dc shoes black       1.00      1.00      1.00         1\n",
            "               denim jeans       0.00      0.00      0.00         1\n",
            "               dish towels       1.00      1.00      1.00         1\n",
            "                duffle bag       1.00      1.00      1.00         1\n",
            "              emerald ring       0.00      0.00      0.00         1\n",
            "         fishnet stockings       0.50      1.00      0.67         1\n",
            "         flannel for women       0.00      0.00      0.00         1\n",
            "     formal shirts for men       0.00      0.00      0.00         1\n",
            "              fur slippers       1.00      1.00      1.00         1\n",
            "                gold dress       0.33      1.00      0.50         1\n",
            "            gold toe socks       1.00      1.00      1.00         1\n",
            "gucci guilty intense women       1.00      1.00      1.00         1\n",
            "          halter neck tops       0.00      0.00      0.00         1\n",
            "               hand warmer       1.00      1.00      1.00         1\n",
            "           hawaiian shirts       1.00      1.00      1.00         1\n",
            "            hollister polo       1.00      1.00      1.00         1\n",
            "                    jacket       1.00      1.00      1.00         1\n",
            "                     kurti       0.00      0.00      0.00         1\n",
            "            lace stockings       0.50      1.00      0.67         1\n",
            "            leather jacket       1.00      1.00      1.00         1\n",
            "                     levis       0.33      1.00      0.50         1\n",
            "         mens dress shirts       0.33      1.00      0.50         1\n",
            "            necklace pearl       0.00      0.00      0.00         1\n",
            "                nike shoes       1.00      1.00      1.00         1\n",
            "                nike women       0.33      1.00      0.50         1\n",
            "                noodle top       0.50      1.00      0.67         1\n",
            "                 one piece       0.00      0.00      0.00         1\n",
            "            oversized tees       0.00      0.00      0.00         1\n",
            "             palazzo pants       0.00      0.00      0.00         1\n",
            "           pants for women       0.00      0.00      0.00         1\n",
            "                pink dress       1.00      1.00      1.00         1\n",
            "         printed cardigans       1.00      1.00      1.00         1\n",
            "              puff sleeves       1.00      1.00      1.00         1\n",
            "                rain boots       1.00      1.00      1.00         1\n",
            "          sarees for women       0.00      0.00      0.00         1\n",
            "          satin night suit       1.00      1.00      1.00         1\n",
            "                     scarf       1.00      1.00      1.00         1\n",
            "              sharara suit       0.00      0.00      0.00         1\n",
            "                     shawl       1.00      1.00      1.00         1\n",
            "            shiffon sarees       1.00      1.00      1.00         1\n",
            "             shirt dresses       0.50      1.00      0.67         1\n",
            "                     shoes       0.00      0.00      0.00         1\n",
            "                    shorts       0.00      0.00      0.00         1\n",
            "              silver jeans       1.00      1.00      1.00         1\n",
            "           silver necklace       1.00      1.00      1.00         1\n",
            "              skater skirt       1.00      1.00      1.00         1\n",
            "             sleveless top       0.50      1.00      0.67         1\n",
            "                snow boots       1.00      1.00      1.00         1\n",
            "             spaghetti top       1.00      1.00      1.00         1\n",
            "         spiderman costume       1.00      1.00      1.00         1\n",
            "          square neck tops       0.50      1.00      0.67         1\n",
            "            steel necklace       1.00      1.00      1.00         1\n",
            "     striped t shirt women       0.00      0.00      0.00         1\n",
            "                  sundress       0.00      0.00      0.00         1\n",
            "                   sweater       1.00      1.00      1.00         1\n",
            "           toddler sandals       1.00      1.00      1.00         1\n",
            "                  tote bag       0.33      1.00      0.50         1\n",
            "             tropical tops       0.00      0.00      0.00         1\n",
            "                    warmer       1.00      1.00      1.00         1\n",
            "                wild jeans       0.50      1.00      0.67         1\n",
            "              wind cheater       1.00      1.00      1.00         1\n",
            " workout clothes for women       1.00      1.00      1.00         1\n",
            "        wrap around skirts       1.00      1.00      1.00         1\n",
            "\n",
            "                  accuracy                           0.73        80\n",
            "                 macro avg       0.62      0.72      0.65        80\n",
            "              weighted avg       0.62      0.72      0.65        80\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#--print the performance report\n",
        "performance_report(df_predicted_vs_actual['Actual_User_Query'],df_predicted_vs_actual['Predicted_User_Query'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G1xhQfJOw1Uh"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oQ1N0eFKw1Uj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "W7BT8U1Nw1Uj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jQFg4LGPw1Uk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mc79lIViw1Uk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "mapping.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}